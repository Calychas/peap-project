{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.utils import read_embeddings_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "df = read_embeddings_dataframe(os.path.join(\"..\", \"datasets\", \"embeddings.csv\"))\r\n",
    "# df = pd.read_pickle(\"embeddings_30_20.pkl.gz\")\r\n",
    "# df = pd.read_pickle(\"embeddings_50_20.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['embedding'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.clustering import perform_clusterings, create_clustering_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = perform_clusterings(df, 5, 5, 0.8)\r\n",
    "create_clustering_files(results, \".\", \"clusters\", \"cluster_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.dimensionality_reduction import create_umap_data_and_model\r\n",
    "from umap import UMAP\r\n",
    "\r\n",
    "create_umap_data_and_model(df, \".\", \"graph_umap\", \"umap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "users = pd.read_csv(\"../datasets/accounts_processed.csv\", index_col=0)\r\n",
    "users['merge'] = users['username'].str.lower()\r\n",
    "old_index = users[users['name'] == \"Zygmunt Frankiewicz\"].index[1]\r\n",
    "users = users.drop(old_index).reset_index()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "umap_df = pd.read_csv(\"graph_umap.csv\")\r\n",
    "cluster_info = pd.read_csv(\"clusters.csv\")\r\n",
    "whole_df = pd.merge(umap_df, cluster_info, on='username')\r\n",
    "whole_df['merge'] = whole_df['username'].str.lower()\r\n",
    "whole_df = pd.merge(whole_df, users, on=\"merge\").drop(columns=[\"username_y\"]).rename(columns={\"username_x\": \"username\"})\r\n",
    "\r\n",
    "whole_df.columns\r\n",
    "whole_df['kmeans_cluster'] = whole_df['kmeans_cluster'].astype(str)\r\n",
    "whole_df['gmm_cluster'] = whole_df['gmm_cluster'].astype(str)\r\n",
    "whole_df['mean_shift_cluster'] = whole_df['mean_shift_cluster'].astype(str)\r\n",
    "\r\n",
    "fig = px.scatter(whole_df, x='2D_x', y='2D_y', color='mean_shift_cluster', hover_data=['username', 'pozycja', 'coalition', 'party', 'name'])\r\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(whole_df, x='3D_x', y='3D_z', z='3D_y', color='coalition', hover_data=['username', 'pozycja', 'coalition', 'party', 'name'])\r\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.clustering import cluster_db_scan\r\n",
    "data = whole_df[['3D_x', '3D_y', '3D_z']].to_numpy()\r\n",
    "model, labels = cluster_db_scan(data, 0.4)\r\n",
    "whole_df['super_dbscan'] = labels\r\n",
    "whole_df['super_dbscan'] = whole_df['super_dbscan'].astype(str)\r\n",
    "fig = px.scatter_3d(whole_df, x='3D_x', y='3D_y', z='3D_z', color='super_dbscan', hover_data=['username'])\r\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.dimensionality_reduction import perform_umap\r\n",
    "import numpy as np\r\n",
    "data = np.array(df[\"embedding\"].tolist())\r\n",
    "umap_10_model, umap_10_reduced = perform_umap(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, umap_10_dbscan = cluster_db_scan(umap_10_reduced, 0.3)\r\n",
    "whole_df['umap_10'] = umap_10_dbscan\r\n",
    "whole_df['umap_10'] = whole_df['umap_10'].astype(str)\r\n",
    "fig = px.scatter_3d(whole_df, x='3D_x', y='3D_y', z='3D_z', color='umap_10', hover_data=['username'])\r\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances \r\n",
    "\r\n",
    "distances = euclidean_distances(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.reshape(distances, -1)\r\n",
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(distances)\r\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../datasets/tweets_cleaned.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = df.sort_values(by=\"tweet_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\r\n",
    "pd.set_option('display.max_columns', None)\r\n",
    "pd.set_option('display.max_colwidth', None)\r\n",
    "\r\n",
    "\r\n",
    "sort[[\"id\", \"tweet\", \"tweet_length\"]].where((sort[\"tweet_length\"] >= 30) & (sort[\"tweet_length\"] < 40)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(sort, x=\"tweet_length\")\r\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort.where((sort[\"tweet_length\"] >= 30) & (sort[\"tweet_length\"] < 40)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df[\"tweet_length\"] >= 30).dropna(how='all')[\"username\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(tweets_dataframe: pd.DataFrame, min_tweet_length: int, min_tweets_number: int):\r\n",
    "    tweet_data = tweets_dataframe[[\"id\", \"username\", \"tweet\", \"tweet_length\"]]\r\n",
    "    long_enough_tweets = tweet_data[tweet_data[\"tweet_length\"] >= min_tweet_length]\r\n",
    "    tweets_by_username_count = long_enough_tweets.groupby(by=\"username\")[[\"id\"]].count()\r\n",
    "    users_to_drop = (\r\n",
    "        tweets_by_username_count[tweets_by_username_count[\"id\"] < min_tweets_number]\r\n",
    "        .reset_index()[\"username\"]\r\n",
    "        .to_list()\r\n",
    "    )\r\n",
    "    df: pd.DataFrame = long_enough_tweets[~long_enough_tweets[\"username\"].isin(users_to_drop)]  # type: ignore\r\n",
    "\r\n",
    "    os.mkdir(f\"embeddings_{min_tweet_length}_{min_tweets_number}\")\r\n",
    "\r\n",
    "    unique_usernames = df[\"username\"].unique().tolist()\r\n",
    "\r\n",
    "\r\n",
    "    usernames = []\r\n",
    "    embeddings = []\r\n",
    "\r\n",
    "    for user in unique_usernames:\r\n",
    "        all_user_tweet_embeddings = pd.read_pickle(f\"../datasets/embeddings/{user}.pkl.gz\")\r\n",
    "        selected = pd.merge(long_enough_tweets, all_user_tweet_embeddings, left_on=\"id\", right_on=\"tweet_id\")[[\"tweet_id\", \"username_x\", \"tweet_embedding\"]].rename(columns={\"username_x\": \"username\"})\r\n",
    "        mean_embedding = np.mean(np.array(selected[\"tweet_embedding\"].tolist()), axis=0)\r\n",
    "        usernames.append(user)\r\n",
    "        embeddings.append(mean_embedding)\r\n",
    "        selected.to_pickle(f\"embeddings_{min_tweet_length}_{min_tweets_number}/{user}.pkl.gz\")\r\n",
    "    \r\n",
    "    user_embeddings = pd.DataFrame({\"username\": usernames, \"embedding\": embeddings})\r\n",
    "    user_embeddings.to_pickle(f\"embeddings_{min_tweet_length}_{min_tweets_number}.pkl.gz\")\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "generate_embeddings(df, 50, 20)\r\n",
    "\r\n",
    "\r\n",
    "# tweet_data = df[[\"id\", \"username\", \"tweet\", \"tweet_length\"]]\r\n",
    "# long_enough_tweets = tweet_data[tweet_data[\"tweet_length\"] >= 30]\r\n",
    "# all_user_tweet_embeddings = pd.read_pickle(f\"../datasets/embeddings/achybicka.pkl.gz\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}