{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "embeddings_df = pd.read_csv(os.path.join(\"..\",\"datasets\", \"embeddings.csv\"))\n",
    "accounts_df = pd.read_csv(os.path.join(\"..\",\"datasets\", \"accounts_processed.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "accounts_df.head(5)\n",
    "accounts_df['username'] = accounts_df['username'].apply(lambda s: s.lower())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         username                                          embedding\n0       achybicka  [-4.93041947e-02 -5.91295818e-03 -8.47795755e-...\n1        ac_sobol  [-8.40702951e-02  6.32756064e-03 -9.36329067e-...\n2      adambielan  [-6.17371537e-02 -1.24293072e-02 -7.66848996e-...\n3      adamgaweda  [ 2.38768775e-02  1.51185095e-02 -8.82171020e-...\n4  adamowiczpawel  [-4.28744927e-02  1.10798636e-02 -9.27639380e-...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>username</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>achybicka</td>\n      <td>[-4.93041947e-02 -5.91295818e-03 -8.47795755e-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ac_sobol</td>\n      <td>[-8.40702951e-02  6.32756064e-03 -9.36329067e-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>adambielan</td>\n      <td>[-6.17371537e-02 -1.24293072e-02 -7.66848996e-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>adamgaweda</td>\n      <td>[ 2.38768775e-02  1.51185095e-02 -8.82171020e-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>adamowiczpawel</td>\n      <td>[-4.28744927e-02  1.10798636e-02 -9.27639380e-...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "embeddings_df['username'] = embeddings_df['username'].astype(object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "full_df = pd.merge(embeddings_df, accounts_df, on='username', how='inner')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "username     548\nembedding    548\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "username         548\nembedding        548\nUnnamed: 0       548\npozycja          548\ncoalition        548\nparty            548\nname             548\nlink do konta    548\ntweets_count     548\ndtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.count()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_to_training = full_df[['embedding','username', 'pozycja', 'coalition', 'party']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Zjednoczona Prawica    236\nKO                     177\nLewica                  54\nniez.                   37\nPSL-Kukiz15             33\nKonfederacja            11\nName: coalition, dtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_training['coalition'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "PiS                             199\nPlatforma Obywatelska           149\nniez.                            55\nSLD                              29\nPSL                              26\nSolidarna Polska                 17\nWiosna                           17\nPorozumienie                     16\nNowoczesna                        7\nKukiz15                           6\nRazem                             6\nKORWiN                            4\nRuch Narodowy                     4\nPartia Zieloni                    3\nBezpartyjni Samorządowcy          3\nKonfederacja                      2\nInicjatywa Polska                 2\nPolska Partia Socjalistyczna      1\nKonfederacja Korony Polskiej      1\nTeraz!                            1\nName: party, dtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_training['party'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Sejm                     373\nSenat                     49\nEuroposeł                 46\nPrezydent miasta          45\nMarszałek Województwa     11\nWojewoda                  11\nPolska 2050               10\nPrezydent Polski           2\nPremier                    1\nName: pozycja, dtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_training['pozycja'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedding_size = 768"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "party_labels = df_to_training['party']\n",
    "coalition_labels = df_to_training['coalition']\n",
    "position_labels = df_to_training['pozycja']\n",
    "parties_number_of_classes = len(party_labels.unique())\n",
    "coalitions_number_of_classes = len(coalition_labels.unique())\n",
    "positions_number_of_classes = len(position_labels.unique())\n",
    "\n",
    "party_labels = party_labels.to_numpy()\n",
    "coalition_labels = coalition_labels.to_numpy()\n",
    "position_labels = position_labels.to_numpy()\n",
    "\n",
    "party_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "party_encoded = party_encoder.fit_transform(party_labels.reshape(-1,1)).toarray()\n",
    "\n",
    "coalition_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "coalition_encoded = coalition_encoder.fit_transform(coalition_labels.reshape(-1,1)).toarray()\n",
    "\n",
    "position_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "position_encoded = position_encoder.fit_transform(position_labels.reshape(-1,1)).toarray()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = df_to_training['embedding']\n",
    "features = list(features)\n",
    "features = [np.fromstring(embedding[1:-1].replace(\"\\n\",\"\"), count=embedding_size, sep=\" \") for embedding in features]\n",
    "features = np.array(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(features)\n",
    "features_scaled = scaler.transform(features)\n",
    "\n",
    "minmax_scaler = MinMaxScaler().fit(features)\n",
    "features_min_max = minmax_scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model_kfold(sklearn_model, splits: int, features_arr, labels, labels_encoder):\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\n",
    "    train_f1_scores = []\n",
    "    val_f1_scores = []\n",
    "\n",
    "    for index, (train_indices, val_indices) in enumerate(skf.split(features_arr, labels)):\n",
    "        train_x, val_x = features_arr[train_indices], features_arr[val_indices]\n",
    "        train_y, val_y = labels[train_indices], labels[val_indices]\n",
    "\n",
    "        train_y = labels_encoder.transform(train_y.reshape(-1,1)).toarray()\n",
    "        val_y = labels_encoder.transform(val_y.reshape(-1,1)).toarray()\n",
    "\n",
    "        train_y, val_y = np.argmax(train_y,axis=1), np.argmax(val_y,axis=1)\n",
    "        sklearn_model.fit(train_x, train_y, )\n",
    "        train_pred = sklearn_model.predict(train_x)\n",
    "        val_pred = sklearn_model.predict(val_x)\n",
    "\n",
    "        train_f1_score = f1_score(train_y, train_pred, average='macro')\n",
    "        val_f_score = f1_score(val_y, val_pred, average='macro')\n",
    "        train_f1_scores.append(train_f1_score)\n",
    "        val_f1_scores.append(val_f_score)\n",
    "    return np.mean(train_f1_scores), np.mean(val_f1_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH_TO_RESULTS = os.path.join(\"..\", \"reports\", \"classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_names =[]\n",
    "train_f1_scores =[]\n",
    "val_f1_scores = []\n",
    "features_names = []\n",
    "cs =[]\n",
    "tols = []\n",
    "\n",
    "for l, encoder, labels_name in [(coalition_labels, coalition_encoder, \"coalitions\"),\n",
    "                   (party_labels, party_encoder, \"parties\"),\n",
    "                   (position_labels, position_encoder, \"positions\")]:\n",
    "    for name, feature in [(\"scaled\", features_scaled),\n",
    "                          (\"original\", features),\n",
    "                          (\"minmax\", features_min_max)]:\n",
    "        for c in [0.1, 0.25, 0.5, 0.75, 1.0]:\n",
    "            for tol in [1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "                lr_model = LogisticRegression(penalty='l2', max_iter=100000, C=c, tol=tol)\n",
    "                mean_train_f1_score, mean_val_f1_score = train_model_kfold(lr_model, 10, feature, l, encoder)\n",
    "                print(f\"Training F1-score: {mean_train_f1_score}, validation F1-score: {mean_val_f1_score},\"\n",
    "                      f\"features - {name}, labels name - {labels_name}, C={c}, tol={tol}\")\n",
    "                label_names.append(labels_name)\n",
    "                train_f1_scores.append(mean_train_f1_score)\n",
    "                val_f1_scores.append(mean_val_f1_score)\n",
    "                features_names.append(name)\n",
    "                cs.append(c)\n",
    "                tols.append(tol)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(data={\"label_name\": label_names,\n",
    "                             \"feature_type\": features_names,\n",
    "                             \"C\": cs,\n",
    "                             \"tol\": tols,\n",
    "                             \"train_f1_score\": train_f1_scores,\n",
    "                             \"val_f1_score\": val_f1_scores})\n",
    "\n",
    "results.to_csv(\n",
    "    os.path.join(PATH_TO_RESULTS, \"logistic_regression.csv\"),\n",
    "    index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_names =[]\n",
    "train_f1_scores =[]\n",
    "val_f1_scores = []\n",
    "features_names = []\n",
    "msss =[]\n",
    "msls = []\n",
    "crits = []\n",
    "\n",
    "for l, encoder, labels_name in [(coalition_labels, coalition_encoder, \"coalitions\"),\n",
    "                   (party_labels, party_encoder, \"parties\"),\n",
    "                   (position_labels, position_encoder, \"positions\")]:\n",
    "    for name, feature in [(\"scaled\", features_scaled),\n",
    "                          (\"original\", features),\n",
    "                          (\"minmax\", features_min_max)]:\n",
    "        for crit in ['gini', 'entropy']:\n",
    "            for mss in range(2,20):\n",
    "                for msl in range(2,20):\n",
    "                    dec_tree = DecisionTreeClassifier(criterion=crit, min_samples_leaf=msl, min_samples_split=mss)\n",
    "                    mean_train_f1_score, mean_val_f1_score = train_model_kfold(dec_tree, 10, feature, l, encoder)\n",
    "                    print(f\"Training F1-score: {mean_train_f1_score}, validation F1-score: {mean_val_f1_score},\"\n",
    "                          f\"features - {name}, labels name - {labels_name}, criterion={crit}, mss={mss}, msl={msl}\")\n",
    "                    label_names.append(labels_name)\n",
    "                    train_f1_scores.append(mean_train_f1_score)\n",
    "                    val_f1_scores.append(mean_val_f1_score)\n",
    "                    features_names.append(name)\n",
    "                    msss.append(mss)\n",
    "                    msls.append(msl)\n",
    "                    crits.append(crit)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(data={\"label_name\": label_names,\n",
    "                             \"feature_type\": features_names,\n",
    "                             \"min_samples_leaf\": msls,\n",
    "                             \"min_samples_split\": msss,\n",
    "                             \"criterion\": crits,\n",
    "                             \"train_f1_score\": train_f1_scores,\n",
    "                             \"val_f1_score\": val_f1_scores})\n",
    "\n",
    "results.to_csv(\n",
    "    os.path.join(PATH_TO_RESULTS, \"decision_tree.csv\"),\n",
    "    index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_names =[]\n",
    "train_f1_scores =[]\n",
    "val_f1_scores = []\n",
    "features_names = []\n",
    "cs =[]\n",
    "tols = []\n",
    "kernels = []\n",
    "\n",
    "for l, encoder, labels_name in [(coalition_labels, coalition_encoder, \"coalitions\"),\n",
    "                   (party_labels, party_encoder, \"parties\"),\n",
    "                   (position_labels, position_encoder, \"positions\")]:\n",
    "    for name, feature in [(\"scaled\", features_scaled),\n",
    "                          (\"original\", features),\n",
    "                          (\"minmax\", features_min_max)]:\n",
    "        for c in [0.1, 0.25, 0.5, 0.75, 1.0]:\n",
    "            for tol in [1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "                for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "                    svm = SVC(kernel=kernel, C=c, tol=tol)\n",
    "                    mean_train_f1_score, mean_val_f1_score = train_model_kfold(svm, 10, feature, l, encoder)\n",
    "                    print(f\"Training F1-score: {mean_train_f1_score}, validation F1-score: {mean_val_f1_score},\"\n",
    "                          f\"features - {name}, labels name - {labels_name}, C={c}, tol={tol}, kernel={kernel}\")\n",
    "                    label_names.append(labels_name)\n",
    "                    train_f1_scores.append(mean_train_f1_score)\n",
    "                    val_f1_scores.append(mean_val_f1_score)\n",
    "                    features_names.append(name)\n",
    "                    cs.append(c)\n",
    "                    tols.append(tol)\n",
    "                    kernels.append(kernel)\n",
    "results = pd.DataFrame(data={\"label_name\": label_names,\n",
    "                             \"feature_type\": features_names,\n",
    "                             \"kernel\": kernels,\n",
    "                             \"C\": cs,\n",
    "                             \"tol\": tols,\n",
    "                             \"train_f1_score\": train_f1_scores,\n",
    "                             \"val_f1_score\": val_f1_scores})\n",
    "\n",
    "results.to_csv(\n",
    "    os.path.join(PATH_TO_RESULTS, \"svm.csv\"),\n",
    "    index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_names =[]\n",
    "train_f1_scores =[]\n",
    "val_f1_scores = []\n",
    "features_names = []\n",
    "neighbours_list =[]\n",
    "weights_list = []\n",
    "distance_list = []\n",
    "\n",
    "for l, encoder, labels_name in [(coalition_labels, coalition_encoder, \"coalitions\"),\n",
    "                   (party_labels, party_encoder, \"parties\"),\n",
    "                   (position_labels, position_encoder, \"positions\")]:\n",
    "    for name, feature in [(\"scaled\", features_scaled),\n",
    "                          (\"original\", features),\n",
    "                          (\"minmax\", features_min_max)]:\n",
    "        for neighbors in [5,10,20,30,40,50]:\n",
    "            for weights in ['uniform', 'distance']:\n",
    "                for distance in ['euclidean', 'manhattan', 'chebyshev', 'minkowski']:\n",
    "                    svm = KNeighborsClassifier(n_neighbors=neighbors, weights=weights, metric=distance)\n",
    "                    mean_train_f1_score, mean_val_f1_score = train_model_kfold(svm, 10, feature, l, encoder)\n",
    "                    print(f\"Training F1-score: {mean_train_f1_score}, validation F1-score: {mean_val_f1_score},\"\n",
    "                          f\"features - {name}, labels name - {labels_name}, n_neighbours={neighbors}, weights={weights}, distance={distance}\")\n",
    "                    label_names.append(labels_name)\n",
    "                    train_f1_scores.append(mean_train_f1_score)\n",
    "                    val_f1_scores.append(mean_val_f1_score)\n",
    "                    features_names.append(name)\n",
    "                    neighbours_list.append(neighbors)\n",
    "                    weights_list.append(weights)\n",
    "                    distance_list.append(distance)\n",
    "\n",
    "results = pd.DataFrame(data={\"label_name\": label_names,\n",
    "                             \"feature_type\": features_names,\n",
    "                             \"distance\": distance_list,\n",
    "                             \"n_neighbours\": neighbours_list,\n",
    "                             \"weights\": weights_list,\n",
    "                             \"train_f1_score\": train_f1_scores,\n",
    "                             \"val_f1_score\": val_f1_scores})\n",
    "\n",
    "results.to_csv(\n",
    "    os.path.join(PATH_TO_RESULTS, \"knn.csv\"),\n",
    "    index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}