{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import fasttext\n",
    "import json\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PATH_TO_DATASETS = \"../datasets\"\n",
    "PATH_TO_POLEMO_CONLL = \"../datasets/polemo/dataset_conll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"train\": os.path.join(PATH_TO_POLEMO_CONLL,\"all.sentence.train_processed.csv\"),\n",
    "    \"dev\": os.path.join(PATH_TO_POLEMO_CONLL,\"all.sentence.dev_processed.csv\"),\n",
    "    \"test\": os.path.join(PATH_TO_POLEMO_CONLL,\"all.sentence.test_processed.csv\"),\n",
    "    \"annotation\": os.path.join(PATH_TO_DATASETS, \"sentiment_data\", \"political_tweets_annotations.csv\")\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "with open(os.path.join(\"..\", \"datasets\", \"emojis.json\"), encoding=\"utf-8\") as f:\n",
    "    emoji_mapping = json.load(f)\n",
    "\n",
    "emoji_mapping_items = emoji_mapping.items()\n",
    "def emoji2text_tweet(tweet: str) -> str:\n",
    "    text = tweet\n",
    "    for emoji, emoji_text in emoji_mapping_items:\n",
    "        text = text.replace(emoji, f\"<{emoji_text}>\")\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def remove_quotes_from_saved_file(txt_path: str):\n",
    "    text = \"\"\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line[0] == \"\\\"\" and line[-2] == \"\\\"\":\n",
    "                line = line[1:]\n",
    "                line = line[:-2] + \"\\n\"\n",
    "            text += line\n",
    "\n",
    "    os.remove(txt_path)\n",
    "\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "data_for_fasttext = {}\n",
    "for dataset, file_path in files.items():\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[['label','text']]\n",
    "    df['label'] = \"__label__\" +  df['label']\n",
    "    df['text'] = df['text'].apply(emoji2text_tweet)\n",
    "    df['text'] = df['text'].apply(lambda string: string.lower())\n",
    "    df['text'] = df['text'].apply(lambda string: string.replace(\"#\",\"\"))\n",
    "    df['row'] = df['label'] + \" \" + df['text']\n",
    "    path = os.path.join(PATH_TO_DATASETS, \"sentiment_data\", f\"{dataset}_data.txt\")\n",
    "    df['row'].to_csv(path, index=False, header=False)\n",
    "    remove_quotes_from_saved_file(path)\n",
    "    data_for_fasttext[dataset] = {}\n",
    "    data_for_fasttext[dataset][\"labels\"] = list(df['label'].values)\n",
    "    data_for_fasttext[dataset][\"texts\"] = list(df['text'].values)\n",
    "    data_for_fasttext[dataset][\"dataframe\"] = df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "tweets_data = data_for_fasttext['annotation']\n",
    "texts_train_val, texts_test, labels_train_val, labels_test = train_test_split(tweets_data['texts'], tweets_data['labels'], test_size=0.1, random_state=42)\n",
    "texts_train, texts_val, labels_train, labels_val = train_test_split(texts_train_val, labels_train_val, test_size=1/9, random_state=42)\n",
    "\n",
    "train_polemo = data_for_fasttext['train']['dataframe'][[\"text\", \"label\"]]\n",
    "val_polemo = data_for_fasttext['dev']['dataframe'][[\"text\", \"label\"]]\n",
    "test_polemo = data_for_fasttext['test']['dataframe'][[\"text\", \"label\"]]\n",
    "\n",
    "train_tweets = pd.DataFrame(data={\"text\": texts_train, \"label\": labels_train})\n",
    "val_tweets = pd.DataFrame(data={\"text\": texts_val, \"label\": labels_val})\n",
    "test_tweets = pd.DataFrame(data={\"text\": texts_test, \"label\": labels_test})\n",
    "\n",
    "train = train_polemo.append(train_tweets)\n",
    "val = val_polemo.append(val_tweets)\n",
    "test = test_polemo.append(test_tweets)\n",
    "\n",
    "train['row'] = train['label'] + \" \" + train['text']\n",
    "val['row'] = val['label'] + \" \" + val['text']\n",
    "test['row'] = test['label'] + \" \" + test['text']\n",
    "\n",
    "train['row'].to_csv(os.path.join(PATH_TO_DATASETS, \"sentiment_data\", f\"full_train_data.txt\"), index=False, header=False)\n",
    "val['row'].to_csv(os.path.join(PATH_TO_DATASETS, \"sentiment_data\", f\"full_val_data.txt\"), index=False, header=False)\n",
    "test['row'].to_csv(os.path.join(PATH_TO_DATASETS, \"sentiment_data\", f\"full_test_data.txt\"), index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier only on PolEmo training data...\n",
      "F1-score for all tweets: 0.29466757589906445\n",
      "F1-score for test set of PolEmo: 0.5874823306117167\n",
      "\n",
      "Training classifier on PolEmo training data and 80% of political tweets\n",
      "F1-score for test set of political tweets: 0.3812850008377031\n",
      "F1-score for test set of PolEmo: 0.5610325791091721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training classifier only on PolEmo training data...\")\n",
    "model =fasttext.train_supervised(input=os.path.join(PATH_TO_DATASETS, \"sentiment_data\", \"train_data.txt\"), wordNgrams=1, neg=5,dim=300, lr=0.005, epoch=500, loss=\"ns\", verbose=1, label_prefix='__label__')\n",
    "test_results = model.predict(data_for_fasttext[\"test\"][\"texts\"])\n",
    "annotation_results = model.predict(data_for_fasttext[\"annotation\"][\"texts\"])\n",
    "\n",
    "print(f\"F1-score for all tweets: {f1_score(annotation_results[0],data_for_fasttext['annotation']['labels'],average='macro')}\")\n",
    "print(f\"F1-score for test set of PolEmo: {f1_score(test_results[0],data_for_fasttext['test']['labels'],average='macro')}\")\n",
    "print()\n",
    "\n",
    "print(\"Training classifier on PolEmo training data and 80% of political tweets\")\n",
    "model =fasttext.train_supervised(input=os.path.join(PATH_TO_DATASETS, \"sentiment_data\", \"full_train_data.txt\"), wordNgrams=1, neg=5,dim=300, lr=0.005, epoch=500, loss=\"ns\", verbose=1, label_prefix='__label__')\n",
    "test_results = model.predict(list(test_polemo[\"text\"].values))\n",
    "annotation_results = model.predict(list(test_tweets['text'].values))\n",
    "\n",
    "print(f\"F1-score for test set of political tweets: {f1_score(annotation_results[0],list(test_tweets['label'].values),average='macro')}\")\n",
    "print(f\"F1-score for test set of PolEmo: {f1_score(test_results[0],list(test_polemo['label'].values),average='macro')}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.34984710896960713\n",
      "F1-score for dev set: 0.5623942811063802\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.34984710896960713\n",
      "F1-score for dev set: 0.5629298826329951\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.34984710896960713\n",
      "F1-score for dev set: 0.562571859518963\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.3500344840528849\n",
      "F1-score for dev set: 0.5629021398226923\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.36152677445247106\n",
      "F1-score for dev set: 0.5582780004991592\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.3601970461953892\n",
      "F1-score for dev set: 0.5592922691828756\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.367239299716516\n",
      "F1-score for dev set: 0.5564198703181898\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.367239299716516\n",
      "F1-score for dev set: 0.5560494890712804\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5706073642332963\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5704664458637649\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5700849443316581\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 1\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.57068949669332\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.41809287758654845\n",
      "F1-score for dev set: 0.5964858413727783\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.41809287758654845\n",
      "F1-score for dev set: 0.5961174314759348\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.41809287758654845\n",
      "F1-score for dev set: 0.5962649553694438\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.41809287758654845\n",
      "F1-score for dev set: 0.5965323319189448\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6031817829531319\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6022700759160577\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.601864468810706\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6015863097213002\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.605732347798267\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6054246922025561\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6056461452059755\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 2\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6041908521269723\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.39900082638419354\n",
      "F1-score for dev set: 0.5902343640042036\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.39900082638419354\n",
      "F1-score for dev set: 0.5899936012340775\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.39900082638419354\n",
      "F1-score for dev set: 0.5897528640697065\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.39900082638419354\n",
      "F1-score for dev set: 0.5898151012624974\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.4330852287247636\n",
      "F1-score for dev set: 0.5964765228893903\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.43242796360266245\n",
      "F1-score for dev set: 0.5963029705464398\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.43242796360266245\n",
      "F1-score for dev set: 0.5950023738027166\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.43242796360266245\n",
      "F1-score for dev set: 0.5942141939826172\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.45773524720893144\n",
      "F1-score for dev set: 0.595838509699971\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.45685341299376386\n",
      "F1-score for dev set: 0.5959876525220141\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.45685341299376386\n",
      "F1-score for dev set: 0.5963027592912202\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 3\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.45685341299376386\n",
      "F1-score for dev set: 0.5961264799049685\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.4287878787878788\n",
      "F1-score for dev set: 0.578241469359867\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.4287878787878788\n",
      "F1-score for dev set: 0.5780949693429496\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.4287878787878788\n",
      "F1-score for dev set: 0.5780318706504539\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.4287878787878788\n",
      "F1-score for dev set: 0.5781989423181655\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.43316610925306576\n",
      "F1-score for dev set: 0.58565814271643\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.43316610925306576\n",
      "F1-score for dev set: 0.5846522159345713\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.43316610925306576\n",
      "F1-score for dev set: 0.5849852841231988\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.43316610925306576\n",
      "F1-score for dev set: 0.5859802479593381\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.45752379550583844\n",
      "F1-score for dev set: 0.5883855813828512\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.45752379550583844\n",
      "F1-score for dev set: 0.5885487698767945\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.45752379550583844\n",
      "F1-score for dev set: 0.5886762355254658\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 4\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.45752379550583844\n",
      "F1-score for dev set: 0.5886762355254658\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.40264388921677924\n",
      "F1-score for dev set: 0.5717001098326694\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.40264388921677924\n",
      "F1-score for dev set: 0.572027866196775\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.40264388921677924\n",
      "F1-score for dev set: 0.5718699674227063\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.40264388921677924\n",
      "F1-score for dev set: 0.5718699674227063\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.578612027993442\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.4885352339814949\n",
      "F1-score for dev set: 0.5793203197874702\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.4627725035161744\n",
      "F1-score for dev set: 0.5767334745329324\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.4885352339814949\n",
      "F1-score for dev set: 0.5750089062371991\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.44657598867835524\n",
      "F1-score for dev set: 0.5799423032404591\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.44657598867835524\n",
      "F1-score for dev set: 0.5807364590481098\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.44657598867835524\n",
      "F1-score for dev set: 0.5807364590481098\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 300\n",
      "Ngram - 5\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.44657598867835524\n",
      "F1-score for dev set: 0.5807364590481098\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.34984710896960713\n",
      "F1-score for dev set: 0.5625205958490247\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.34984710896960713\n",
      "F1-score for dev set: 0.5617300653618835\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.34984710896960713\n",
      "F1-score for dev set: 0.5626973463916634\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.34984710896960713\n",
      "F1-score for dev set: 0.5623865660464368\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.36612220873339957\n",
      "F1-score for dev set: 0.5564832202428006\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.36612220873339957\n",
      "F1-score for dev set: 0.5578504995255673\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.367239299716516\n",
      "F1-score for dev set: 0.5563937762031202\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.3611425339366516\n",
      "F1-score for dev set: 0.5551823336884754\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5705791619755132\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5694953991109653\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5708618017026222\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 1\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5695170101135963\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.3986903083248243\n",
      "F1-score for dev set: 0.5960740521596544\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.3986903083248243\n",
      "F1-score for dev set: 0.5960522855118234\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.3986903083248243\n",
      "F1-score for dev set: 0.5958891375307778\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.3986903083248243\n",
      "F1-score for dev set: 0.5959014017503925\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6024626999103988\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6024241284092978\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6008479437826201\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6006420705828094\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6038631575992107\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6047068496903283\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6043803336380296\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 2\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6043846940144177\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.41569928137092316\n",
      "F1-score for dev set: 0.5876384828014878\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.41569928137092316\n",
      "F1-score for dev set: 0.5887840972994121\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.41569928137092316\n",
      "F1-score for dev set: 0.5881732757452676\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.41569928137092316\n",
      "F1-score for dev set: 0.5880546767550845\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.4330852287247636\n",
      "F1-score for dev set: 0.5962680358700545\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.43242796360266245\n",
      "F1-score for dev set: 0.5968775810451735\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.43242796360266245\n",
      "F1-score for dev set: 0.5951143331641728\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.43242796360266245\n",
      "F1-score for dev set: 0.5943461994806127\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.45773524720893144\n",
      "F1-score for dev set: 0.5964579763289016\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.45773524720893144\n",
      "F1-score for dev set: 0.5961063100557479\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.45773524720893144\n",
      "F1-score for dev set: 0.596329579869589\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 3\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.45773524720893144\n",
      "F1-score for dev set: 0.5963056140151539\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.42163633467981293\n",
      "F1-score for dev set: 0.5767430521840395\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.42163633467981293\n",
      "F1-score for dev set: 0.5767313243560706\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.42163633467981293\n",
      "F1-score for dev set: 0.5765753511024818\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.42163633467981293\n",
      "F1-score for dev set: 0.5765931618705866\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.43316610925306576\n",
      "F1-score for dev set: 0.5855133146722856\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.43316610925306576\n",
      "F1-score for dev set: 0.5845263915117236\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.43316610925306576\n",
      "F1-score for dev set: 0.5851894549453599\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.43316610925306576\n",
      "F1-score for dev set: 0.585169571399017\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.45752379550583844\n",
      "F1-score for dev set: 0.5878358317484796\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.45752379550583844\n",
      "F1-score for dev set: 0.5871059184116542\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.45752379550583844\n",
      "F1-score for dev set: 0.587897041775314\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 4\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.45752379550583844\n",
      "F1-score for dev set: 0.5881741909456453\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.40264388921677924\n",
      "F1-score for dev set: 0.5698290272947197\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.40264388921677924\n",
      "F1-score for dev set: 0.5696321884357409\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.40264388921677924\n",
      "F1-score for dev set: 0.5698290272947197\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.40264388921677924\n",
      "F1-score for dev set: 0.5698033238253848\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5781318888545635\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.4885352339814949\n",
      "F1-score for dev set: 0.580648497585905\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.4885352339814949\n",
      "F1-score for dev set: 0.5782755314640016\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.4885352339814949\n",
      "F1-score for dev set: 0.5773602750116107\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.4393732492997199\n",
      "F1-score for dev set: 0.5788925140297055\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.4393732492997199\n",
      "F1-score for dev set: 0.5795021232622986\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.44657598867835524\n",
      "F1-score for dev set: 0.5786816349500974\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 500\n",
      "Ngram - 5\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.44657598867835524\n",
      "F1-score for dev set: 0.5796255100354513\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.34984710896960713\n",
      "F1-score for dev set: 0.5632997887206401\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.3500344840528849\n",
      "F1-score for dev set: 0.5627443738750487\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.3500344840528849\n",
      "F1-score for dev set: 0.5634742391696247\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.3500344840528849\n",
      "F1-score for dev set: 0.5629397978184261\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.36612220873339957\n",
      "F1-score for dev set: 0.557038219265292\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.3600246477577898\n",
      "F1-score for dev set: 0.5581052282131655\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.37326506587625674\n",
      "F1-score for dev set: 0.5568494278760834\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.37326506587625674\n",
      "F1-score for dev set: 0.5552685793608568\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5701158764554315\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5694119001074792\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5693101927126345\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 1000\n",
      "Ngram - 1\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.38135152696556207\n",
      "F1-score for dev set: 0.5700904054979502\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.3986903083248243\n",
      "F1-score for dev set: 0.5946319975901299\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.3986903083248243\n",
      "F1-score for dev set: 0.5943110117810346\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.3986903083248243\n",
      "F1-score for dev set: 0.5948872064014958\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.3986903083248243\n",
      "F1-score for dev set: 0.5943293136436751\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6026093285004853\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6018275226901302\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6013123296488856\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.43428995485045774\n",
      "F1-score for dev set: 0.6007268472771755\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6043218635195131\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6044032434171132\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6042658336779875\n",
      "\n",
      "Loss method - softmax\n",
      "Dim - 1000\n",
      "Ngram - 2\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.41696254486785334\n",
      "F1-score for dev set: 0.6048047717004964\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 3\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.41569928137092316\n",
      "F1-score for dev set: 0.5880047168330594\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 3\n",
      "Negative samples - 10\n",
      "F1-score for all tweets: 0.41569928137092316\n",
      "F1-score for dev set: 0.588038206554259\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 3\n",
      "Negative samples - 15\n",
      "F1-score for all tweets: 0.41569928137092316\n",
      "F1-score for dev set: 0.5881203378409153\n",
      "\n",
      "Loss method - hs\n",
      "Dim - 1000\n",
      "Ngram - 3\n",
      "Negative samples - 20\n",
      "F1-score for all tweets: 0.39900082638419354\n",
      "F1-score for dev set: 0.5876451344999448\n",
      "\n",
      "Loss method - ns\n",
      "Dim - 1000\n",
      "Ngram - 3\n",
      "Negative samples - 5\n",
      "F1-score for all tweets: 0.4330852287247636\n",
      "F1-score for dev set: 0.5960209072677074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dims = []\n",
    "ngrams = []\n",
    "losses = []\n",
    "negs = []\n",
    "tweets_f1_scores = []\n",
    "dev_f1_scores = []\n",
    "for dim in [300, 500]:\n",
    "    for ngram in [1,2,3,4,5]:\n",
    "        for method in [\"hs\", \"ns\", \"softmax\"]:\n",
    "            for neg in [5,10,15,20]:\n",
    "                model =fasttext.train_supervised(input=os.path.join(PATH_TO_DATASETS, \"sentiment_data\", \"full_train_data.txt\"), wordNgrams=ngram, neg=neg,dim=dim, lr=0.005, epoch=500, loss=method, verbose=1, label_prefix='__label__')\n",
    "                dev_results = model.predict(list(val_polemo[\"text\"].values))\n",
    "                annotation_results = model.predict(list(val_tweets[\"text\"].values))\n",
    "                dims.append(dim)\n",
    "                ngrams.append(ngram)\n",
    "                losses.append(method)\n",
    "                negs.append(neg)\n",
    "                tweets_f1_scores.append(f1_score(annotation_results[0],list(val_tweets['label'].values),average='macro'))\n",
    "                dev_f1_scores.append(f1_score(dev_results[0],list(val_polemo['label'].values),average='macro'))\n",
    "                print(f\"Loss method - {method}\")\n",
    "                print(f\"Dim - {dim}\")\n",
    "                print(f\"Ngram - {ngram}\")\n",
    "                print(f\"Negative samples - {neg}\")\n",
    "                print(f\"F1-score for all tweets: {tweets_f1_scores[-1]}\")\n",
    "                print(f\"F1-score for dev set: {dev_f1_scores[-1]}\")\n",
    "                print()\n",
    "\n",
    "results = pd.DataFrame(data={\"dim\": dims,\n",
    "                             \"ngram\" : ngrams,\n",
    "                             \"loss\": losses,\n",
    "                             \"neg\": negs,\n",
    "                             \"tweets_f1_score\": tweets_f1_scores,\n",
    "                             \"dev_f1_score\": dev_f1_scores})\n",
    "\n",
    "results.to_csv(os.path.join(\"..\",\"reports\",\"sentiment_classification_results.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate - 0.001\n",
      "Epochs - 100\n",
      "F1-score for all tweets: 0.47309228143815873\n",
      "F1-score for dev set: 0.5781176034831482\n",
      "\n",
      "Learning rate - 0.001\n",
      "Epochs - 250\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5784146579599303\n",
      "\n",
      "Learning rate - 0.001\n",
      "Epochs - 500\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5781948930981358\n",
      "\n",
      "Learning rate - 0.001\n",
      "Epochs - 1000\n",
      "F1-score for all tweets: 0.47309228143815873\n",
      "F1-score for dev set: 0.5783590817567723\n",
      "\n",
      "Learning rate - 0.005\n",
      "Epochs - 100\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5780887910650374\n",
      "\n",
      "Learning rate - 0.005\n",
      "Epochs - 250\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5784509443199565\n",
      "\n",
      "Learning rate - 0.005\n",
      "Epochs - 500\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5784146579599303\n",
      "\n",
      "Learning rate - 0.005\n",
      "Epochs - 1000\n",
      "F1-score for all tweets: 0.47309228143815873\n",
      "F1-score for dev set: 0.57761176966198\n",
      "\n",
      "Learning rate - 0.0001\n",
      "Epochs - 100\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5780887910650374\n",
      "\n",
      "Learning rate - 0.0001\n",
      "Epochs - 250\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5781346902195486\n",
      "\n",
      "Learning rate - 0.0001\n",
      "Epochs - 500\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5784218082786423\n",
      "\n",
      "Learning rate - 0.0001\n",
      "Epochs - 1000\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5783499336950164\n",
      "\n",
      "Learning rate - 0.0005\n",
      "Epochs - 100\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.5785388886528873\n",
      "\n",
      "Learning rate - 0.0005\n",
      "Epochs - 250\n",
      "F1-score for all tweets: 0.47309228143815873\n",
      "F1-score for dev set: 0.5783968903042601\n",
      "\n",
      "Learning rate - 0.0005\n",
      "Epochs - 500\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.577554363960377\n",
      "\n",
      "Learning rate - 0.0005\n",
      "Epochs - 1000\n",
      "F1-score for all tweets: 0.4989115474077759\n",
      "F1-score for dev set: 0.578612027993442\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-23-ec4e10658599>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m lr_epoch_results = pd.DataFrame(data={\"dim\": dims,\n\u001B[0m\u001B[0;32m     21\u001B[0m                              \u001B[1;34m\"ngram\"\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mngrams\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m                              \u001B[1;34m\"loss\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mlosses\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dims' is not defined"
     ]
    }
   ],
   "source": [
    "lrs = []\n",
    "epochs = []\n",
    "tweets_f1_scores = []\n",
    "dev_f1_scores = []\n",
    "for lr in [0.001, 0.005, 0.0001, 0.0005]:\n",
    "    for epoch in [100,250,500,1000]:\n",
    "        model =fasttext.train_supervised(input=os.path.join(PATH_TO_DATASETS, \"sentiment_data\", \"full_train_data.txt\"), wordNgrams=5, neg=5,dim=300, lr=0.005, epoch=500, loss=\"ns\", verbose=1, label_prefix='__label__')\n",
    "        dev_results = model.predict(list(val_polemo[\"text\"].values))\n",
    "        annotation_results = model.predict(list(val_tweets[\"text\"].values))\n",
    "        lrs.append(lr)\n",
    "        epochs.append(epoch)\n",
    "        tweets_f1_scores.append(f1_score(annotation_results[0],list(val_tweets['label'].values),average='macro'))\n",
    "        dev_f1_scores.append(f1_score(dev_results[0],list(val_polemo['label'].values),average='macro'))\n",
    "        print(f\"Learning rate - {lr}\")\n",
    "        print(f\"Epochs - {epoch}\")\n",
    "        print(f\"F1-score for all tweets: {tweets_f1_scores[-1]}\")\n",
    "        print(f\"F1-score for dev set: {dev_f1_scores[-1]}\")\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "lr_epoch_results = pd.DataFrame(data={\"lr\": lrs,\n",
    "                             \"epoch\" : epochs,\n",
    "                             \"tweets_f1_score\": tweets_f1_scores,\n",
    "                             \"dev_f1_score\": dev_f1_scores})\n",
    "\n",
    "lr_epoch_results.to_csv(os.path.join(\"..\",\"reports\",\"sentiment_classification_lr_epoch_results.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-d8e3d76ce18a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mdev_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_polemo\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"text\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mannotation_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_tweets\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"text\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mdims\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mngrams\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mngram\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mlosses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dims' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model =fasttext.train_supervised(input=os.path.join(PATH_TO_DATASETS, \"sentiment_data\", \"full_train_data.txt\"), wordNgrams=5, neg=10,dim=1000, lr=0.005, epoch=500, loss=\"ns\", verbose=1, label_prefix='__label__', thread=4)\n",
    "dev_results = model.predict(list(val_polemo[\"text\"].values))\n",
    "annotation_results = model.predict(list(val_tweets[\"text\"].values))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for all tweets: 0.4885352339814949\n",
      "F1-score for dev set: 0.580118322998199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1-score for all tweets: {f1_score(annotation_results[0],list(val_tweets['label'].values),average='macro')}\")\n",
    "print(f\"F1-score for dev set: {f1_score(dev_results[0],list(val_polemo['label'].values),average='macro')}\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for political tweets\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "__label__ambiguous       0.67      0.36      0.47        11\n",
      " __label__negative       0.38      0.53      0.44        19\n",
      "  __label__neutral       0.42      0.63      0.51        27\n",
      " __label__positive       0.66      0.45      0.53        47\n",
      "\n",
      "          accuracy                           0.50       104\n",
      "         macro avg       0.53      0.49      0.49       104\n",
      "      weighted avg       0.55      0.50      0.50       104\n",
      "\n",
      "Classification report for polemo data\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "__label__ambiguous       0.42      0.19      0.26       689\n",
      " __label__negative       0.61      0.84      0.71      2122\n",
      "  __label__neutral       0.71      0.61      0.66      1427\n",
      " __label__positive       0.74      0.64      0.69      1509\n",
      "\n",
      "          accuracy                           0.65      5747\n",
      "         macro avg       0.62      0.57      0.58      5747\n",
      "      weighted avg       0.65      0.65      0.64      5747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for political tweets\")\n",
    "print(classification_report(list(val_tweets['label'].values), annotation_results[0]))\n",
    "\n",
    "print(\"Classification report for polemo data\")\n",
    "print(classification_report(list(val_polemo['label'].values), dev_results[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}