{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm.auto import tqdm\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation based on pretrained models\n",
    "\n",
    "Each section should work individually,\n",
    "as long as all files used in it are already available"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 1 - drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_pickle('../datasets/tweets.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered = tweets[['username', 'id', 'link', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered.to_pickle('../datasets/for_presentation/tweets_raw.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 2 - join with users/parties/coalitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered = pd.read_pickle('../datasets/for_presentation/tweets_raw.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv('../datasets/accounts_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "users = users[['username', 'party', 'coalition', 'pozycja']]\n",
    "users = users.rename(columns={'pozycja': 'role'})\n",
    "users['username'] = users['username'].apply(str.lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users = filtered.merge(users, on='username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users.to_pickle('../datasets/for_presentation/tweets_with_party_coalition.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Stage 3 - calculate sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = fasttext.load_model('../trained_models/sentiment_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_emojied2text.pkl.gz')\n",
    "tweets_users = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets['tweet'] = clean_tweets['tweet'].apply(str.lower)\n",
    "clean_tweets = clean_tweets[['id', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "just_tweets = clean_tweets['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 1.64 s, total: 1min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictions = sentiment_model.predict(just_tweets)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = [label for sublist in predictions for label in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets['sentiment'] = predictions\n",
    "clean_tweets = clean_tweets[['id', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment = tweets_users.merge(clean_tweets, on='id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment.replace(to_replace={\n",
    "    '__label__positive': 'positive',\n",
    "    '__label__negative': 'negative',\n",
    "    '__label__ambiguous': 'ambiguous',\n",
    "    '__label__neutral': 'neutral'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "negative     551675\nneutral      440461\npositive     361306\nambiguous    137464\nName: sentiment, dtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_users_sentiment['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment.to_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Stage 4 - calculate topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_lemma_stopwords.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)\n",
    "\n",
    "with open('../trained_models/lda_10.pkl.gz', 'rb') as lda_file:\n",
    "    lda: LatentDirichletAllocation = pkl.load(lda_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_texts = clean_tweets.tweet.tolist()\n",
    "counts = vectorizer.transform(tweets_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "probas = lda.transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = np.argmax(probas, axis=1)\n",
    "prob_values = np.max(probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets['topic'] = labels\n",
    "clean_tweets['topic_proba'] = prob_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets = clean_tweets[['id', 'topic', 'topic_proba']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment_topic = tweets_users_sentiment.merge(clean_tweets, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment_topic.to_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Topics\n",
    "\n",
    "### Words per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)\n",
    "\n",
    "with open('../trained_models/lda_10.pkl.gz', 'rb') as lda_file:\n",
    "    lda: LatentDirichletAllocation = pkl.load(lda_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_in_topics = {}\n",
    "\n",
    "for topic_num, topic in enumerate(lda.components_):\n",
    "    frequencies = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq in zip(vectorizer.get_feature_names(), topic)\n",
    "    ]\n",
    "    words_in_topics[topic_num] = frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "with open('../datasets/for_presentation/words_per_topic.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(words_in_topics, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Extra - visualisation of topics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(lda.components_)):\n",
    "    topic = lda.components_[i]\n",
    "    frequencies = {name: freq for name, freq in zip(vectorizer.get_feature_names(), topic)}\n",
    "    wordcloud = WordCloud(\n",
    "        width=1920, height=1080, background_color=\"white\"\n",
    "    ).generate_from_frequencies(frequencies=frequencies)\n",
    "    fig = px.imshow(wordcloud, title=f\"Topic {i}\")\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Topics per user/party/coalition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_lemma_stopwords.pkl.gz')\n",
    "\n",
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)\n",
    "\n",
    "with open('../trained_models/lda_10.pkl.gz', 'rb') as lda_file:\n",
    "    lda: LatentDirichletAllocation = pkl.load(lda_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "topics_count = len(lda.components_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tweets_texts = clean_tweets.tweet.tolist()\n",
    "counts = vectorizer.transform(tweets_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "probas = lda.transform(counts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "tweets_users_sentiment_topic = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')\n",
    "a = clean_tweets.merge(tweets_users_sentiment_topic, on='id')\n",
    "a.rename(columns={'username_x': 'username'}, inplace=True)\n",
    "a = a.reset_index()\n",
    "\n",
    "def get_topic_distribution_for_column(column_value, column_name):\n",
    "    indices = np.array(a[a[column_name]==column_value].index.tolist())\n",
    "    topics = probas[indices]\n",
    "    values = np.sum(topics, axis=0)\n",
    "    distribution = values / np.sum(values)\n",
    "    return distribution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "topics_distributions = {\n",
    "    'per_user': {},\n",
    "    'per_party': {},\n",
    "    'per_coalition': {}\n",
    "}\n",
    "\n",
    "unique_usernames = a.username.unique()\n",
    "unique_parties = a.party.unique()\n",
    "unique_coalitions = a.coalition.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=538.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d45cdd944bf445b4833b125b352bd93a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for username in tqdm(unique_usernames):\n",
    "    topics_distributions['per_user'][username] = [\n",
    "        {\n",
    "            'topic': t,\n",
    "            'part': p\n",
    "        }\n",
    "        for t, p\n",
    "        in zip(range(topics_count), get_topic_distribution_for_column(\n",
    "            column_name='username',\n",
    "            column_value=username))\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3d06e654da4477483b8d0093586478f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for party in tqdm(unique_parties):\n",
    "    topics_distributions['per_party'][party] = [\n",
    "        {\n",
    "            'topic': t,\n",
    "            'part': p\n",
    "        }\n",
    "        for t, p\n",
    "        in zip(range(topics_count), get_topic_distribution_for_column(\n",
    "            column_name='party',\n",
    "            column_value=party))\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bab8bd86bd384f3b891913231ce63816"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for coalition in tqdm(unique_coalitions):\n",
    "    topics_distributions['per_coalition'][coalition] = [\n",
    "        {\n",
    "            'topic': t,\n",
    "            'part': p\n",
    "        }\n",
    "        for t, p\n",
    "        in zip(range(topics_count), get_topic_distribution_for_column(\n",
    "            column_name='coalition',\n",
    "            column_value=coalition))\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "with open('../datasets/for_presentation/topics_distributions.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(topics_distributions, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Words\n",
    "\n",
    "### Words per user/party/coalition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_lemma_stopwords.pkl.gz')\n",
    "tweets_users_sentiment_topic = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')\n",
    "a = clean_tweets.merge(tweets_users_sentiment_topic, on='id', suffixes=('', '_y'))\n",
    "a.rename(columns={'username_x': 'username'}, inplace=True)\n",
    "a.reset_index(inplace=True)\n",
    "\n",
    "del clean_tweets\n",
    "del tweets_users_sentiment_topic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "counts = vectorizer.transform(a.tweet.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def get_word_counts_for_column(column_name, column_value):\n",
    "    indices = np.array(a[a[column_name]==column_value].index.tolist())\n",
    "    words = counts[indices]\n",
    "    summed = np.sum(words, axis=0)\n",
    "    return np.array(summed).squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "words_counts = {\n",
    "    'per_user': {},\n",
    "    'per_party': {},\n",
    "    'per_coalition': {}\n",
    "}\n",
    "\n",
    "unique_usernames = a.username.unique()\n",
    "unique_parties = a.party.unique()\n",
    "unique_coalitions = a.coalition.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=538.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "385c851f232a4426b3c2a7ac0756cac5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for username in tqdm(unique_usernames):\n",
    "    words_counts['per_user'][username] = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq\n",
    "        in zip(\n",
    "            vectorizer.get_feature_names(),\n",
    "            get_word_counts_for_column(\n",
    "                column_name='username',\n",
    "                column_value=username\n",
    "            )\n",
    "        )\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccb38ba4d0484f72995a891d4e0e04d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for party in tqdm(unique_parties):\n",
    "    words_counts['per_party'][party] = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq\n",
    "        in zip(\n",
    "            vectorizer.get_feature_names(),\n",
    "            get_word_counts_for_column(\n",
    "                column_name='party',\n",
    "                column_value=party\n",
    "            )\n",
    "        )\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24cf9e42a72949aea66475aa968e046a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for coalition in tqdm(unique_coalitions):\n",
    "    words_counts['per_coalition'][coalition] = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq\n",
    "        in zip(\n",
    "            vectorizer.get_feature_names(),\n",
    "            get_word_counts_for_column(\n",
    "                column_name='coalition',\n",
    "                column_value=coalition\n",
    "            )\n",
    "        )\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "with open('../datasets/for_presentation/words_counts.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(words_counts, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment\n",
    "\n",
    "### Sentiment per user/party/coalition/topic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "a = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "sent_values = a.sentiment.unique()\n",
    "\n",
    "def get_sentiment_distribution_by_column(column_name, column_value):\n",
    "    sent_counts = a[a[column_name] == column_value].sentiment.value_counts()\n",
    "    tweets_count = sent_counts.sum()\n",
    "    result = []\n",
    "    for sent in sent_values:\n",
    "        if sent in sent_counts.index:\n",
    "            result.append((sent, sent_counts[sent] / tweets_count))\n",
    "        else:\n",
    "            result.append((sent, 0))\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "sentiment_distributions = {\n",
    "    'per_user': {},\n",
    "    'per_party': {},\n",
    "    'per_coalition': {},\n",
    "    'per_topic': {}\n",
    "}\n",
    "\n",
    "unique_usernames = a.username.unique()\n",
    "unique_parties = a.party.unique()\n",
    "unique_coalitions = a.coalition.unique()\n",
    "unique_topics = a.topic.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=538.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19284e06f61f4c0c828b9b110b061ab5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for username in tqdm(unique_usernames):\n",
    "    sentiment_distributions['per_user'][username] = get_sentiment_distribution_by_column(\n",
    "        column_name='username',\n",
    "        column_value=username\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4f726d41d674cdfb58ab0ba50264ade"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in tqdm(unique_topics):\n",
    "    sentiment_distributions['per_topic'][topic] = get_sentiment_distribution_by_column(\n",
    "        column_name='topic',\n",
    "        column_value=topic\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97b8328ab9284e94a3a7d2016efcdb53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for party in tqdm(unique_parties):\n",
    "    sentiment_distributions['per_party'][party] = get_sentiment_distribution_by_column(\n",
    "        column_name='party',\n",
    "        column_value=party\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6ffc1b99112400a999db90162c1c001"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for coalition in tqdm(unique_coalitions):\n",
    "    sentiment_distributions['per_coalition'][coalition] = get_sentiment_distribution_by_column(\n",
    "        column_name='coalition',\n",
    "        column_value=coalition\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "with(open('../datasets/for_presentation/sentiment_distributions.pkl.gz', 'wb')) as f:\n",
    "    pkl.dump(sentiment_distributions, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Coalitions and parties\n",
    "\n",
    "### Extract info about each party and coalition for quicker access"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "accounts = pd.read_csv('../datasets/accounts_processed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "parties = accounts.groupby('party').max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "parties.reset_index(inplace=True)\n",
    "parties = parties[['party', 'coalition']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "parties.to_csv('../datasets/for_presentation/parties.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graph positions\n",
    "\n",
    "### t-SNE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tweets = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')\n",
    "usernames = tweets.username.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "embedding_data = pd.read_csv('../datasets/embeddings.csv')\n",
    "embedding_data['username'] = embedding_data['username'].str.lower()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "embedding_data = embedding_data[embedding_data['username'].isin(usernames)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(538, 768)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.array([np.array([np.float(i) for i in x.replace(\"]\", \"\").replace(\"[\", \"\").split()]) for x in embedding_data['embedding'].tolist()])\n",
    "embeddings.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.6 s, sys: 37.4 ms, total: 47.6 s\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tsne3d = TSNE(n_components=3).fit_transform(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 s, sys: 67.5 ms, total: 33.9 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tsne2d = TSNE(n_components=2).fit_transform(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embeddings_normalized = Normalizer().fit_transform(embeddings)\n",
    "embeddings_standardized = StandardScaler().fit_transform(embeddings)\n",
    "\n",
    "tsne3d_standardized = TSNE(n_components=3).fit_transform(embeddings_standardized)\n",
    "tsne3d_normalized = TSNE(n_components=3).fit_transform(embeddings_normalized)\n",
    "\n",
    "tsne2d_standardized = TSNE(n_components=2).fit_transform(embeddings_standardized)\n",
    "tsne2d_normalized = TSNE(n_components=2).fit_transform(embeddings_normalized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "graph_positions = pd.DataFrame(tsne3d, columns=['3D_x', '3D_y', '3D_z'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "graph_positions['2D_x'] = tsne2d[:, 0]\n",
    "graph_positions['2D_y'] = tsne2d[:, 1]\n",
    "graph_positions['username'] = usernames"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "graph_positions.to_csv('../datasets/for_presentation/graph_tsne.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clusters\n",
    "\n",
    "### KMeans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(538, 768)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')\n",
    "usernames = tweets.username.unique()\n",
    "\n",
    "embedding_data = pd.read_csv('../datasets/embeddings.csv')\n",
    "embedding_data['username'] = embedding_data['username'].str.lower()\n",
    "\n",
    "embedding_data = embedding_data[embedding_data['username'].isin(usernames)]\n",
    "\n",
    "embeddings = np.array([np.array([np.float(i) for i in x.replace(\"]\", \"\").replace(\"[\", \"\").split()]) for x in embedding_data['embedding'].tolist()])\n",
    "embeddings.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "clusters = KMeans(n_clusters=6).fit(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(usernames, columns=['username'])\n",
    "df['kmeans_cluster'] = clusters.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/for_presentation/clusters.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}