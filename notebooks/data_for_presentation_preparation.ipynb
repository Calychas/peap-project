{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm.auto import tqdm\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation based on pretrained models\n",
    "\n",
    "Each section should work individually,\n",
    "as long as all files used in it are already available"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 1 - drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_pickle('../datasets/tweets.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered = tweets[['username', 'id', 'link', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered.to_pickle('../datasets/for_presentation/tweets_raw.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 2 - join with users/parties/coalitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered = pd.read_pickle('../datasets/for_presentation/tweets_raw.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv('../datasets/accounts_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "users = users[['username', 'party', 'coalition', 'pozycja']]\n",
    "users = users.rename(columns={'pozycja': 'role'})\n",
    "users['username'] = users['username'].apply(str.lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users = filtered.merge(users, on='username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users.to_pickle('../datasets/for_presentation/tweets_with_party_coalition.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Stage 3 - calculate sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = fasttext.load_model('../trained_models/sentiment_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_emojied2text.pkl.gz')\n",
    "tweets_users = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets['tweet'] = clean_tweets['tweet'].apply(str.lower)\n",
    "clean_tweets = clean_tweets[['id', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "just_tweets = clean_tweets['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 1.52 s, total: 1min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictions = sentiment_model.predict(just_tweets)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = [label for sublist in predictions for label in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets['sentiment'] = predictions\n",
    "clean_tweets = clean_tweets[['id', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment = tweets_users.merge(clean_tweets, on='id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment.replace(to_replace={\n",
    "    '__label__positive': 'positive',\n",
    "    '__label__negative': 'negative',\n",
    "    '__label__ambiguous': 'ambiguous',\n",
    "    '__label__neutral': 'neutral'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative     551675\n",
       "neutral      440461\n",
       "positive     361306\n",
       "ambiguous    137464\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_users_sentiment['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment.to_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Stage 4 - calculate topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_lemma_stopwords.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)\n",
    "\n",
    "with open('../trained_models/lda_10.pkl.gz', 'rb') as lda_file:\n",
    "    lda: LatentDirichletAllocation = pkl.load(lda_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_texts = clean_tweets.tweet.tolist()\n",
    "counts = vectorizer.transform(tweets_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "probas = lda.transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = np.argmax(probas, axis=1)\n",
    "prob_values = np.max(probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets['topic'] = labels\n",
    "clean_tweets['topic_proba'] = prob_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets = clean_tweets[['id', 'topic', 'topic_proba']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment_topic = tweets_users_sentiment.merge(clean_tweets, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment_topic.to_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Topics\n",
    "\n",
    "### Words per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)\n",
    "\n",
    "with open('../trained_models/lda_10.pkl.gz', 'rb') as lda_file:\n",
    "    lda: LatentDirichletAllocation = pkl.load(lda_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_in_topics = {}\n",
    "\n",
    "for topic_num, topic in enumerate(lda.components_):\n",
    "    frequencies = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq in zip(vectorizer.get_feature_names(), topic)\n",
    "    ]\n",
    "    words_in_topics[topic_num] = frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "with open('../datasets/for_presentation/words_per_topic.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(words_in_topics, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Extra - visualisation of topics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(lda.components_)):\n",
    "    topic = lda.components_[i]\n",
    "    frequencies = {name: freq for name, freq in zip(vectorizer.get_feature_names(), topic)}\n",
    "    wordcloud = WordCloud(\n",
    "        width=1920, height=1080, background_color=\"white\"\n",
    "    ).generate_from_frequencies(frequencies=frequencies)\n",
    "    fig = px.imshow(wordcloud, title=f\"Topic {i}\")\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Topics per user/party/coalition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_lemma_stopwords.pkl.gz')\n",
    "\n",
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)\n",
    "\n",
    "with open('../trained_models/lda_10.pkl.gz', 'rb') as lda_file:\n",
    "    lda: LatentDirichletAllocation = pkl.load(lda_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topics_count = len(lda.components_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tweets_texts = clean_tweets.tweet.tolist()\n",
    "counts = vectorizer.transform(tweets_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "probas = lda.transform(counts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "tweets_users_sentiment_topic = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')\n",
    "a = clean_tweets.merge(tweets_users_sentiment_topic, on='id')\n",
    "a.rename(columns={'username_x': 'username'}, inplace=True)\n",
    "a = a.reset_index()\n",
    "\n",
    "def get_topic_distribution_for_column(column_value, column_name):\n",
    "    indices = np.array(a[a[column_name]==column_value].index.tolist())\n",
    "    topics = probas[indices]\n",
    "    values = np.sum(topics, axis=0)\n",
    "    distribution = values / np.sum(values)\n",
    "    return distribution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "topics_distributions = {\n",
    "    'per_user': {},\n",
    "    'per_party': {},\n",
    "    'per_coalition': {}\n",
    "}\n",
    "\n",
    "unique_usernames = a.username.unique()\n",
    "unique_parties = a.party.unique()\n",
    "unique_coalitions = a.coalition.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=538.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f8343ad46cf42adbeadc73784212f8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for username in tqdm(unique_usernames):\n",
    "    topics_distributions['per_user'][username] = [\n",
    "        {\n",
    "            'topic': t,\n",
    "            'part': p\n",
    "        }\n",
    "        for t, p\n",
    "        in zip(range(topics_count), get_topic_distribution_for_column(\n",
    "            column_name='username',\n",
    "            column_value=username))\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c2ef02b81864198b6074c7ac87c8d6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for party in tqdm(unique_parties):\n",
    "    topics_distributions['per_party'][party] = [\n",
    "        {\n",
    "            'topic': t,\n",
    "            'part': p\n",
    "        }\n",
    "        for t, p\n",
    "        in zip(range(topics_count), get_topic_distribution_for_column(\n",
    "            column_name='party',\n",
    "            column_value=party))\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5f01f475e0c452ca3565daa1d515c2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for coalition in tqdm(unique_coalitions):\n",
    "    topics_distributions['per_coalition'][coalition] = [\n",
    "        {\n",
    "            'topic': t,\n",
    "            'part': p\n",
    "        }\n",
    "        for t, p\n",
    "        in zip(range(topics_count), get_topic_distribution_for_column(\n",
    "            column_name='coalition',\n",
    "            column_value=coalition))\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "with open('../datasets/for_presentation/topics_distributions.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(topics_distributions, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Words\n",
    "\n",
    "### Words per user/party/coalition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_lemma_stopwords.pkl.gz')\n",
    "tweets_users_sentiment_topic = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')\n",
    "a = clean_tweets.merge(tweets_users_sentiment_topic, on='id', suffixes=('', '_y'))\n",
    "a.rename(columns={'username_x': 'username'}, inplace=True)\n",
    "a.reset_index(inplace=True)\n",
    "\n",
    "del clean_tweets\n",
    "del tweets_users_sentiment_topic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "counts = vectorizer.transform(a.tweet.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def get_word_counts_for_column(column_name, column_value):\n",
    "    indices = np.array(a[a[column_name]==column_value].index.tolist())\n",
    "    words = counts[indices]\n",
    "    summed = np.sum(words, axis=0)\n",
    "    return np.array(summed).squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "words_counts = {\n",
    "    'per_user': {},\n",
    "    'per_party': {},\n",
    "    'per_coalition': {}\n",
    "}\n",
    "\n",
    "unique_usernames = a.username.unique()\n",
    "unique_parties = a.party.unique()\n",
    "unique_coalitions = a.coalition.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=538.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b59a4e0ea334e96b775e1ae533fec6d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for username in tqdm(unique_usernames):\n",
    "    words_counts['per_user'][username] = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq\n",
    "        in zip(\n",
    "            vectorizer.get_feature_names(),\n",
    "            get_word_counts_for_column(\n",
    "                column_name='username',\n",
    "                column_value=username\n",
    "            )\n",
    "        )\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f94eb4d4cf54782bca90c917534a34a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for party in tqdm(unique_parties):\n",
    "    words_counts['per_party'][party] = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq\n",
    "        in zip(\n",
    "            vectorizer.get_feature_names(),\n",
    "            get_word_counts_for_column(\n",
    "                column_name='party',\n",
    "                column_value=party\n",
    "            )\n",
    "        )\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b55e889f993a458aaeca3a9cf26ce5cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for coalition in tqdm(unique_coalitions):\n",
    "    words_counts['per_coalition'][coalition] = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq\n",
    "        in zip(\n",
    "            vectorizer.get_feature_names(),\n",
    "            get_word_counts_for_column(\n",
    "                column_name='coalition',\n",
    "                column_value=coalition\n",
    "            )\n",
    "        )\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "with open('../datasets/for_presentation/words_counts.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(words_counts, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment\n",
    "\n",
    "### Sentiment per user/party/coalition/topic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "a = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "sent_values = a.sentiment.unique()\n",
    "\n",
    "def get_sentiment_distribution_by_column(column_name, column_value):\n",
    "    sent_counts = a[a[column_name] == column_value].sentiment.value_counts()\n",
    "    tweets_count = sent_counts.sum()\n",
    "    result = []\n",
    "    for sent in sent_values:\n",
    "        if sent in sent_counts.index:\n",
    "            result.append((sent, sent_counts[sent] / tweets_count))\n",
    "        else:\n",
    "            result.append((sent, 0))\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "sentiment_distributions = {\n",
    "    'per_user': {},\n",
    "    'per_party': {},\n",
    "    'per_coalition': {},\n",
    "    'per_topic': {}\n",
    "}\n",
    "\n",
    "unique_usernames = a.username.unique()\n",
    "unique_parties = a.party.unique()\n",
    "unique_coalitions = a.coalition.unique()\n",
    "unique_topics = a.topic.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=538.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36e9400faeab4884b2625bf535cd3a57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for username in tqdm(unique_usernames):\n",
    "    sentiment_distributions['per_user'][username] = get_sentiment_distribution_by_column(\n",
    "        column_name='username',\n",
    "        column_value=username\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f9efca60bf44a70992ad74327b36fed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in tqdm(unique_topics):\n",
    "    sentiment_distributions['per_topic'][topic] = get_sentiment_distribution_by_column(\n",
    "        column_name='topic',\n",
    "        column_value=topic\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6240ce9453b843a48e5540e1e1fff2c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for party in tqdm(unique_parties):\n",
    "    sentiment_distributions['per_party'][party] = get_sentiment_distribution_by_column(\n",
    "        column_name='party',\n",
    "        column_value=party\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bde946552cba478190f15c41af361404"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for coalition in tqdm(unique_coalitions):\n",
    "    sentiment_distributions['per_coalition'][coalition] = get_sentiment_distribution_by_column(\n",
    "        column_name='coalition',\n",
    "        column_value=coalition\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "with(open('../datasets/for_presentation/sentiment_distributions.pkl.gz', 'wb')) as f:\n",
    "    pkl.dump(sentiment_distributions, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}