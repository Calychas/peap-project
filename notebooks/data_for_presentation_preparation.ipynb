{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from tqdm.auto import tqdm\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from src.models.train_herbert_sentiment_model import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data preparation based on pretrained models\n",
    "\n",
    "Each section should work individually,\n",
    "as long as all files used in it are already available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 1 - drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_pickle('../datasets/tweets.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered = tweets[['username', 'id', 'link', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered.to_pickle('../datasets/for_presentation/tweets_raw.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 2 - join with users/parties/coalitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered = pd.read_pickle('../datasets/for_presentation/tweets_raw.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv('../datasets/accounts_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "users = users[['username', 'party', 'coalition', 'pozycja']]\n",
    "users = users.rename(columns={'pozycja': 'role'})\n",
    "users['username'] = users['username'].apply(str.lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users = filtered.merge(users, on='username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users.to_pickle('../datasets/for_presentation/tweets_with_party_coalition.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Stage 3 - calculate sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=538.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b2cd458ba52497eb5a9cc9616931b4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "emb_files = []\n",
    "\n",
    "for filename in tqdm(os.listdir('../datasets/embeddings')):\n",
    "    emb_files.append(pd.read_pickle(f'../datasets/embeddings/{filename}').drop(columns=['username']))\n",
    "\n",
    "embeddings = pd.concat(emb_files)\n",
    "\n",
    "del emb_files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_model = torch.load('../trained_models/sentiment_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "with open(\"../trained_models/sentiment_encoder.pkl\",'rb') as file:\n",
    "    encoder = pkl.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "emb = np.vstack(embeddings['tweet_embedding'].to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "emb_t = torch.Tensor(emb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = sentiment_model(emb_t)\n",
    "    max_idx = torch.argmax(preds, 1, keepdim=True)\n",
    "    one_hot = torch.FloatTensor(preds.shape)\n",
    "    one_hot.zero_()\n",
    "    one_hot.scatter_(1, max_idx, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "sentiment = encoder.inverse_transform(one_hot.detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "embeddings['sentiment'] = sentiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "neutral      1474278\npositive       14605\nambiguous       1190\nnegative         833\nName: sentiment, dtype: int64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1490906, 4])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tweets_users = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition.pkl.gz')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tweets_users = pd.merge(tweets_users, embeddings, left_on='id', right_on='tweet_id', how='right')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 1.64 s, total: 1min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictions = sentiment_model.predict(just_tweets)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = [label for sublist in predictions for label in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets['sentiment'] = predictions\n",
    "clean_tweets = clean_tweets[['id', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment = tweets_users.merge(clean_tweets, on='id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment.replace(to_replace={\n",
    "    '__label__positive': 'positive',\n",
    "    '__label__negative': 'negative',\n",
    "    '__label__ambiguous': 'ambiguous',\n",
    "    '__label__neutral': 'neutral'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative     551675\n",
       "neutral      440461\n",
       "positive     361306\n",
       "ambiguous    137464\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_users_sentiment['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment.to_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Stage 4 - calculate topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_lemma_stopwords.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)\n",
    "\n",
    "with open('../trained_models/lda_10.pkl.gz', 'rb') as lda_file:\n",
    "    lda: LatentDirichletAllocation = pkl.load(lda_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_texts = clean_tweets.tweet.tolist()\n",
    "counts = vectorizer.transform(tweets_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "probas = lda.transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = np.argmax(probas, axis=1)\n",
    "prob_values = np.max(probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets['topic'] = labels\n",
    "clean_tweets['topic_proba'] = prob_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets = clean_tweets[['id', 'topic', 'topic_proba']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment_topic = tweets_users_sentiment.merge(clean_tweets, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment_topic.to_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Topics\n",
    "\n",
    "### Words per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)\n",
    "\n",
    "with open('../trained_models/lda_10.pkl.gz', 'rb') as lda_file:\n",
    "    lda: LatentDirichletAllocation = pkl.load(lda_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_in_topics = {}\n",
    "\n",
    "for topic_num, topic in enumerate(lda.components_):\n",
    "    frequencies = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq in zip(vectorizer.get_feature_names(), topic)\n",
    "    ]\n",
    "    frequencies.sort(key=lambda x: x['value'], reverse=True)\n",
    "    words_in_topics[topic_num] = frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../datasets/for_presentation/words_per_topic.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(words_in_topics, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Extra - visualisation of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(lda.components_)):\n",
    "    topic = lda.components_[i]\n",
    "    frequencies = {name: freq for name, freq in zip(vectorizer.get_feature_names(), topic)}\n",
    "    wordcloud = WordCloud(\n",
    "        width=1920, height=1080, background_color=\"white\"\n",
    "    ).generate_from_frequencies(frequencies=frequencies)\n",
    "    fig = px.imshow(wordcloud, title=f\"Topic {i}\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Topics per user/party/coalition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_lemma_stopwords.pkl.gz')\n",
    "\n",
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)\n",
    "\n",
    "with open('../trained_models/lda_10.pkl.gz', 'rb') as lda_file:\n",
    "    lda: LatentDirichletAllocation = pkl.load(lda_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "topics_count = len(lda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_texts = clean_tweets.tweet.tolist()\n",
    "counts = vectorizer.transform(tweets_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "probas = lda.transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_users_sentiment_topic = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')\n",
    "a = clean_tweets.merge(tweets_users_sentiment_topic, on='id')\n",
    "a.rename(columns={'username_x': 'username'}, inplace=True)\n",
    "a = a.reset_index()\n",
    "\n",
    "def get_topic_distribution_for_column(column_value, column_name):\n",
    "    indices = np.array(a[a[column_name]==column_value].index.tolist())\n",
    "    topics = probas[indices]\n",
    "    values = np.sum(topics, axis=0)\n",
    "    distribution = values / np.sum(values)\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "topics_distributions = {\n",
    "    'per_user': {},\n",
    "    'per_party': {},\n",
    "    'per_coalition': {}\n",
    "}\n",
    "\n",
    "unique_usernames = a.username.unique()\n",
    "unique_parties = a.party.unique()\n",
    "unique_coalitions = a.coalition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45cdd944bf445b4833b125b352bd93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=538.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for username in tqdm(unique_usernames):\n",
    "    topics_distributions['per_user'][username] = [\n",
    "        {\n",
    "            'topic': t,\n",
    "            'part': p\n",
    "        }\n",
    "        for t, p\n",
    "        in zip(range(topics_count), get_topic_distribution_for_column(\n",
    "            column_name='username',\n",
    "            column_value=username))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d06e654da4477483b8d0093586478f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for party in tqdm(unique_parties):\n",
    "    topics_distributions['per_party'][party] = [\n",
    "        {\n",
    "            'topic': t,\n",
    "            'part': p\n",
    "        }\n",
    "        for t, p\n",
    "        in zip(range(topics_count), get_topic_distribution_for_column(\n",
    "            column_name='party',\n",
    "            column_value=party))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab8bd86bd384f3b891913231ce63816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for coalition in tqdm(unique_coalitions):\n",
    "    topics_distributions['per_coalition'][coalition] = [\n",
    "        {\n",
    "            'topic': t,\n",
    "            'part': p\n",
    "        }\n",
    "        for t, p\n",
    "        in zip(range(topics_count), get_topic_distribution_for_column(\n",
    "            column_name='coalition',\n",
    "            column_value=coalition))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../datasets/for_presentation/topics_distributions.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(topics_distributions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Words\n",
    "\n",
    "### Words per user/party/coalition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_tweets = pd.read_pickle('../datasets/tweets_cleaned_lemma_stopwords.pkl.gz')\n",
    "tweets_users_sentiment_topic = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')\n",
    "a = clean_tweets.merge(tweets_users_sentiment_topic, on='id', suffixes=('', '_y'))\n",
    "a.rename(columns={'username_x': 'username'}, inplace=True)\n",
    "a.reset_index(inplace=True)\n",
    "\n",
    "del clean_tweets\n",
    "del tweets_users_sentiment_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../trained_models/vectorizer_10.pkl.gz', 'rb') as vec_file:\n",
    "    vectorizer: CountVectorizer = pkl.load(vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "counts = vectorizer.transform(a.tweet.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_word_counts_for_column(column_name, column_value):\n",
    "    indices = np.array(a[a[column_name]==column_value].index.tolist())\n",
    "    words = counts[indices]\n",
    "    summed = np.sum(words, axis=0)\n",
    "    return np.array(summed).squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "words_counts = {\n",
    "    'per_user': {},\n",
    "    'per_party': {},\n",
    "    'per_coalition': {}\n",
    "}\n",
    "\n",
    "unique_usernames = a.username.unique()\n",
    "unique_parties = a.party.unique()\n",
    "unique_coalitions = a.coalition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e5708039ad4627b26f0ddce6b18e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=538.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for username in tqdm(unique_usernames):\n",
    "    tmp = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq\n",
    "        in zip(\n",
    "            vectorizer.get_feature_names(),\n",
    "            get_word_counts_for_column(\n",
    "                column_name='username',\n",
    "                column_value=username\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    tmp.sort(key=lambda x: x['value'], reverse=True)\n",
    "    words_counts['per_user'][username] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689dbebba0f74f468e33a688f2df52a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for party in tqdm(unique_parties):\n",
    "    tmp = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq\n",
    "        in zip(\n",
    "            vectorizer.get_feature_names(),\n",
    "            get_word_counts_for_column(\n",
    "                column_name='party',\n",
    "                column_value=party\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    tmp.sort(key=lambda x: x['value'], reverse=True)\n",
    "    words_counts['per_party'][party] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c1f07d7907447ab3b526479e1fabfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for coalition in tqdm(unique_coalitions):\n",
    "    tmp = [\n",
    "        {\n",
    "            'text': name,\n",
    "            'value': freq\n",
    "        }\n",
    "        for name, freq\n",
    "        in zip(\n",
    "            vectorizer.get_feature_names(),\n",
    "            get_word_counts_for_column(\n",
    "                column_name='coalition',\n",
    "                column_value=coalition\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    tmp.sort(key=lambda x: x['value'], reverse=True)\n",
    "    words_counts['per_coalition'][coalition] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../datasets/for_presentation/words_counts.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(words_counts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sentiment\n",
    "\n",
    "### Sentiment per user/party/coalition/topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sent_values = ['negative', 'neutral', 'positive', 'ambiguous']\n",
    "\n",
    "def get_sentiment_distribution_by_column(column_name, column_value):\n",
    "    sent_counts = a[a[column_name] == column_value].sentiment.value_counts()\n",
    "    tweets_count = sent_counts.sum()\n",
    "    result = []\n",
    "    for sent in sent_values:\n",
    "        if sent in sent_counts.index:\n",
    "            result.append((sent, sent_counts[sent] / tweets_count))\n",
    "        else:\n",
    "            result.append((sent, 0))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_distributions = {\n",
    "    'per_user': {},\n",
    "    'per_party': {},\n",
    "    'per_coalition': {},\n",
    "    'per_topic': {}\n",
    "}\n",
    "\n",
    "unique_usernames = a.username.unique()\n",
    "unique_parties = a.party.unique()\n",
    "unique_coalitions = a.coalition.unique()\n",
    "unique_topics = a.topic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c8968b4bce4089acf68f3536050f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=538.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for username in tqdm(unique_usernames):\n",
    "    sentiment_distributions['per_user'][username] = get_sentiment_distribution_by_column(\n",
    "        column_name='username',\n",
    "        column_value=username\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e902ab314d6a4866a6911d6180e34773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in tqdm(unique_topics):\n",
    "    sentiment_distributions['per_topic'][topic] = get_sentiment_distribution_by_column(\n",
    "        column_name='topic',\n",
    "        column_value=topic\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f984685826c841ea88b807bc9d833db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for party in tqdm(unique_parties):\n",
    "    sentiment_distributions['per_party'][party] = get_sentiment_distribution_by_column(\n",
    "        column_name='party',\n",
    "        column_value=party\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588820e105104f6db00ede5c2c00468a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for coalition in tqdm(unique_coalitions):\n",
    "    sentiment_distributions['per_coalition'][coalition] = get_sentiment_distribution_by_column(\n",
    "        column_name='coalition',\n",
    "        column_value=coalition\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with(open('../datasets/for_presentation/sentiment_distributions.pkl.gz', 'wb')) as f:\n",
    "    pkl.dump(sentiment_distributions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Coalitions and parties\n",
    "\n",
    "### Extract info about each party and coalition for quicker access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accounts = pd.read_csv('../datasets/accounts_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parties = accounts.groupby('party').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parties.reset_index(inplace=True)\n",
    "parties = parties[['party', 'coalition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parties.to_csv('../datasets/for_presentation/parties.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Graph positions\n",
    "\n",
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')\n",
    "usernames = tweets.username.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embedding_data = pd.read_csv('../datasets/embeddings.csv')\n",
    "embedding_data['username'] = embedding_data['username'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embedding_data = embedding_data[embedding_data['username'].isin(usernames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.array([np.array([np.float(i) for i in x.replace(\"]\", \"\").replace(\"[\", \"\").split()]) for x in embedding_data['embedding'].tolist()])\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.6 s, sys: 37.4 ms, total: 47.6 s\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tsne3d = TSNE(n_components=3).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 s, sys: 67.5 ms, total: 33.9 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tsne2d = TSNE(n_components=2).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_normalized = Normalizer().fit_transform(embeddings)\n",
    "embeddings_standardized = StandardScaler().fit_transform(embeddings)\n",
    "\n",
    "tsne3d_standardized = TSNE(n_components=3).fit_transform(embeddings_standardized)\n",
    "tsne3d_normalized = TSNE(n_components=3).fit_transform(embeddings_normalized)\n",
    "\n",
    "tsne2d_standardized = TSNE(n_components=2).fit_transform(embeddings_standardized)\n",
    "tsne2d_normalized = TSNE(n_components=2).fit_transform(embeddings_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_positions = pd.DataFrame(tsne3d, columns=['3D_x', '3D_y', '3D_z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_positions['2D_x'] = tsne2d[:, 0]\n",
    "graph_positions['2D_y'] = tsne2d[:, 1]\n",
    "graph_positions['username'] = usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_positions.to_csv('../datasets/for_presentation/graph_tsne.csv', index=False)\n",
    "\n",
    "def calc_clustering_and_graph(self, embedding: np.ndarray):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Clusters\n",
    "\n",
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_pickle('../datasets/for_presentation/tweets_with_party_coalition_sentiment_topic.pkl.gz')\n",
    "usernames = tweets.username.unique()\n",
    "\n",
    "embedding_data = pd.read_csv('../datasets/embeddings.csv')\n",
    "embedding_data['username'] = embedding_data['username'].str.lower()\n",
    "\n",
    "embedding_data = embedding_data[embedding_data['username'].isin(usernames)]\n",
    "\n",
    "embeddings = np.array([np.array([np.float(i) for i in x.replace(\"]\", \"\").replace(\"[\", \"\").split()]) for x in embedding_data['embedding'].tolist()])\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clusters = KMeans(n_clusters=6).fit(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../trained_models/kmeans.pkl.gz', 'wb') as f:\n",
    "    pkl.dump(clusters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(usernames, columns=['username'])\n",
    "df['kmeans_cluster'] = clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/for_presentation/clusters.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}